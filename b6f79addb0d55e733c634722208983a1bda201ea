{
  "comments": [
    {
      "key": {
        "uuid": "07f24f33_47982701",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T21:04:13Z",
      "side": 1,
      "message": "Have you thought about other solutions not using a shared filesystem?",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d6aab8c4_4199c8bf",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T21:30:31Z",
      "side": 1,
      "message": "I discuss several alternatives in the doc, please take a look.",
      "parentUuid": "07f24f33_47982701",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "89eedb7d_1bf21f99",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T21:37:27Z",
      "side": 1,
      "message": "The only one I\u0027ve found is:\n\"Since the current filesystem based storage exists and can be enhanced fairly easily to satisfy the desired use case as a polling based sharing solution, the extra expense of other sharing solutions does not currently seem worth considering.\"\n\nCan you point me to the exact section where you analyse a non-shared filesystem based alternative for distributing the replication load across masters?",
      "parentUuid": "d6aab8c4_4199c8bf",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "39ec1d82_f93e93f0",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T21:55:25Z",
      "side": 1,
      "message": "That is what I am referring to. Please comment there if you don\u0027t understand or have more specific questions.",
      "parentUuid": "89eedb7d_1bf21f99",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4f697336_4fc8e80c",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T22:01:31Z",
      "side": 1,
      "message": "OK, will comment there.",
      "parentUuid": "39ec1d82_f93e93f0",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "cbe030ac_24945f56",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T22:01:31Z",
      "side": 1,
      "message": "The shared filesystem storage has problems too:\n- latency\n- concurrent locking\n- stale file handles\n- caching issues\n- lack of real-time notifications\n\nYou are basically saying that you did not believe it was worth to think about any other solution other than reusing the shared filesystem, just because it is there.\n\nI understand the point, however, it goes against the design-driven approach IMHO, where we asked whoever proposed a solution to think about other possible solutions.",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "852d4965_c80197b5",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T22:58:48Z",
      "side": 1,
      "message": "\u003e The shared filesystem storage has problems too:\n\n\u003e - latency\n\nI am assuming this is not a repeat of the concern below about \"real-time\", so perhaps it refers to persistence latency, and or directory listing latency? It likely has lower or comparable persistence latency to most other solutions. For this use case, the persistence latency does not seem to specifically be very important. As for directory listings, I believe there are many ways to improve the design via sharding and file attributes to decrease this latency if this becomes an issue. The lack of sharding is likely already a replication persistence problem with the current plugin and likely should be dealt with even without this solution.\n\n\u003e - concurrent locking\n\nI believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\n\u003e - stale file handles\n\nAside from potentially interrupting code execution, these are likely not disruptive since they are effectively file not founds which can easily be handled.\n\n\u003e - caching issues\n\nI believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\nWithout jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\n\u003e - lack of real-time notifications\n\nI think you mean event vs polling (since real-time and Gerrit are not really compatible)? I address this in the next section.\n\n\u003e You are basically saying that you did not believe it was worth to think about any other solution other than reusing the shared filesystem, just because it is there.\n\nI am saying that other storage mechanism have extra expenses and the expense list is huge. Here are some obvious expenses: developing a new persistent mechanism, adding external tools to maintain, likely lower reliability due to extra moving parts, likely more communication overhead, likely more libraries to manage with more version compatibility issues, likely more expertise needed to manage, likely more RAM usage, and the list goes on...\n\n\u003e I understand the point, however, it goes against the design-driven approach IMHO, where we asked whoever proposed a solution to think about other possible solutions.\n\nI believe I listed about 6 of them. It is true that I have not listed any explicit alternate sharing mechanisms as all the ones I can think of would suffer the extra expenses that I mention. Do you have any specific suggestions that you believe do not suffer extra expenses?",
      "parentUuid": "cbe030ac_24945f56",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a96e654d_7d9e9ee7",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T09:59:48Z",
      "side": 1,
      "message": "\u003e \u003e The shared filesystem storage has problems too:\n\u003e \n\u003e \u003e - latency\n\u003e \n\u003e I am assuming this is not a repeat of the concern below about \"real-time\", so perhaps it refers to persistence latency, and or directory listing latency? \n\nWith NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\nIn our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\nUsing other shared replication queue implementation (e.g. a message broker) would resolve this problem and reduce latency to msecs.\n\nWhy not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\n\u003e \u003e - concurrent locking\n\u003e \n\u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\nIt depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\nHaving something more granular, it would results in tens of thousands of directories that would eventually slow down the overall system.\n\n\u003e \u003e - stale file handles\n\u003e \n\u003e Aside from potentially interrupting code execution, these are likely not disruptive since they are effectively file not founds which can easily be handled.\n\nAck.\n\n\u003e \u003e - caching issues\n\u003e \n\u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \n\u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\nWe tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\n\u003e \u003e - lack of real-time notifications\n\u003e \n\u003e I think you mean event vs polling (since real-time and Gerrit are not really compatible)? I address this in the next section.\n\nAck.",
      "parentUuid": "852d4965_c80197b5",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c52d5e11_67dfb29c",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T17:26:02Z",
      "side": 1,
      "message": "\u003e With NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\nNo matter how long the shared filesystem delay is, it should not be problematic for the use case where the same shared filesystem is being used to share the git repos since the git data will be limited by this delay also. I.E. there is no point knowing about a pending replication event on another node before the git objects for that event are available to replicate on the other node.\n\n\u003e In our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\nI would like to ask that you please keep in mind the scope of the review of this solution to my use case (which is not about reducing latency).\n\n\u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\nThis sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below). \n\nTechnical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\n\u003e \u003e \u003e - concurrent locking\n\u003e \u003e \n\u003e \u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\u003e \n\u003e It depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\nPerhaps we are talking about different URIs than I am? I am talking about the URI in the current ReplicationTasksStorage.UriUpdate.uri object, perhaps you are talking about the entry in the replication.config file? My approach leads to the same level of locking that is currently seen with a single node. For my use case it is desirable to keep this level of locking in order to prevent having more masters from adding more load to destination resources than the load created by a single node.\n\n\u003e \u003e \u003e - caching issues\n\u003e \u003e \n\u003e \u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \u003e \n\u003e \u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\u003e \n\u003e We tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\nOn second thought, I don\u0027t believe this is relevant since as I pointed out above, having replication coordination that is faster than git coordination does not provide any benefit to the use case being solved.",
      "parentUuid": "a96e654d_7d9e9ee7",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2c85412f_c242e70e",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T19:27:12Z",
      "side": 1,
      "message": "\u003e \u003e With NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\u003e \n\u003e No matter how long the shared filesystem delay is, it should not be problematic for the use case where the same shared filesystem is being used to share the git repos since the git data will be limited by this delay also. I.E. there is no point knowing about a pending replication event on another node before the git objects for that event are available to replicate on the other node.\n\nNFS is caching the files attributes, not the file content. If you know that a file exists on the other node, you will be able to read it. The problem is that you cannot discover that the file exists through attributes because they are cached and thus can\u0027t be trusted. (see the trustfolderstats flag in JGit config)\n\n\u003e \u003e In our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\u003e \n\u003e I would like to ask that you please keep in mind the scope of the review of this solution to my use case (which is not about reducing latency).\n\nScalability means not increasing latency also, but keep the same comparable level of service.\n\n\u003e \u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\u003e \n\u003e This sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below).\n\nIt is a storage alternative: using a proper pub/sub system for storing the replication events rather than a shared filesystem.\n\n\u003e Technical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\nHave you seen the recent evolutions of the replication plugin, about refs filtering? It exposes an interface that is implemented by other plugins. It is possible and we use it also for the multi-site plugin. Happy to showcase how it works at the next forthcoming Gerrit User Summit \u0026 Hackathon in Sunnyvale :-)\n\n\u003e \u003e \u003e \u003e - concurrent locking\n\u003e \u003e \u003e \n\u003e \u003e \u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\u003e \u003e \n\u003e \u003e It depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\u003e \n\u003e Perhaps we are talking about different URIs than I am? I am talking about the URI in the current ReplicationTasksStorage.UriUpdate.uri object, perhaps you are talking about the entry in the replication.config file? My approach leads to the same level of locking that is currently seen with a single node. For my use case it is desirable to keep this level of locking in order to prevent having more masters from adding more load to destination resources than the load created by a single node.\n\nGotcha, so it is one lock per repository. We will end up potentially creating tens of thousands of directories on the filesystem, which will be a major slowdown for NFS servers. NFS is very sensitive in terms of performance to the number of items in a directory.\n\nHave you done some benchmarking on the slowdown generated by the implementation of those locks using individual directories?\n\n\u003e \u003e \u003e \u003e - caching issues\n\u003e \u003e \u003e \n\u003e \u003e \u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\u003e \u003e \n\u003e \u003e We tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\u003e \n\u003e On second thought, I don\u0027t believe this is relevant since as I pointed out above, having replication coordination that is faster than git coordination does not provide any benefit to the use case being solved.\n\nSee my comment above: I am talking about caching of the file attributes, not of the file contents.",
      "parentUuid": "c52d5e11_67dfb29c",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "89a31b45_db839962",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T19:47:24Z",
      "side": 1,
      "message": "\u003e NFS is caching the files attributes, not the file content. If you know that a file exists on the other node, you will be able to read it. The problem is that you cannot discover that the file exists through attributes because they are cached and thus can\u0027t be trusted. (see the trustfolderstats flag in JGit config)\n\nI am not sure how you think this affects my particular use case, maybe you can read the rest of the solution and position this concern on the specific piece that you think would be problematic. I am only planning on using file attributes (the time) as a reference point for scheduling delays.\n\n\u003e Scalability means not increasing latency also, but keep the same comparable level of service.\n\nAgreed, do you see a specific place where this would be reduced by this solution over the current replication plugin?\n\n\u003e \u003e \u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\u003e \u003e \n\u003e \u003e This sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below).\n\u003e \n\u003e It is a storage alternative: using a proper pub/sub system for storing the replication events rather than a shared filesystem.\n\nMy use case is not about improving the storage mechanism.\n\n\u003e \u003e Technical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\u003e \n\u003e Have you seen the recent evolutions of the replication plugin, about refs filtering? It exposes an interface that is implemented by other plugins. It is possible and we use it also for the multi-site plugin. Happy to showcase how it works at the next forthcoming Gerrit User Summit \u0026 Hackathon in Sunnyvale :-)\n\nI look forward to hearing more about this.\n\n\u003e Gotcha, so it is one lock per repository. We will end up potentially creating tens of thousands of directories on the filesystem, which will be a major slowdown for NFS servers. NFS is very sensitive in terms of performance to the number of items in a directory.\n\nSince there are always fewer URI directories than task files, this solution will actually improve the current sharding over the current storage mechanism.\n\n\u003e Have you done some benchmarking on the slowdown generated by the implementation of those locks using individual directories?\n\nI have not benchmarked the current storage mechanism, it could be problematic for us, if it is I will work on sharding it better. However, this specific use case is not trying to solve that problem if it exists.\n\nAs mentioned above, the proposed solution of putting the running tasks in a directory per URI should scale better than the current solution of putting all the running tasks in the same directory.",
      "parentUuid": "2c85412f_c242e70e",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "415f1e3c_4f88f97a",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T20:03:15Z",
      "side": 1,
      "message": "\u003e \u003e NFS is caching the files attributes, not the file content. If you know that a file exists on the other node, you will be able to read it. The problem is that you cannot discover that the file exists through attributes because they are cached and thus can\u0027t be trusted. (see the trustfolderstats flag in JGit config)\n\u003e \n\u003e I am not sure how you think this affects my particular use case, maybe you can read the rest of the solution and position this concern on the specific piece that you think would be problematic. I am only planning on using file attributes (the time) as a reference point for scheduling delays.\n\nTo help clarify, the proposed solution allows distributing replication to other nodes when the nodes are ready. Any caching delays added by a shared filesystem caching layer will not add any latency to the current node if it is ready to replicate a task (i.e. this proposal should not make things worse than what exists today). I see no reason to believe that the potential delays experienced by other nodes would not be acceptable and inline with the proposed use case. If you do see a problem for my use case, or the current use of the plugin, I hope you can point out where more specifically in the detailed design sections below.",
      "parentUuid": "89a31b45_db839962",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b649d125_3014bc2f",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T20:09:26Z",
      "side": 1,
      "message": "\u003e \u003e Scalability means not increasing latency also, but keep the same comparable level of service.\n\u003e \n\u003e Agreed, do you see a specific place where this would be reduced by this solution over the current replication plugin?\n\nThe latency today is:\nT0) ref-update happens, replication event scheduled after D time (for us is 1 second)\nT1 \u003d T0 + D) replication starts\n\nThe latency tomorrow with the storage of events on NFS is:\nT0) ref-update happens, replication event stored on NFS, with latency L time (for busy NFS servers, could even be 60 seconds)\nT1 \u003d T0 + L) replication starts\n\nThe NFS solution increases latency by the NFS cache propagation time, which could be up to 2 minutes.\n\nWe do want to scale our replication tasks as well, without delaying the replication tasks to the NFS caching TTL.\n\nIf you use a different pluggable storage for the storage of the replication events, maybe one without this massive propagation delay, you don\u0027t have this substantial degradation.\n\nP.S. Adding up to 59 more seconds of replication lag is a problem for us. You could say that this solution is for *your* use-case only, where you don\u0027t suffer any NFS cache TTL :-) and I respect that. Let\u0027s make it pluggable so that you can have your shared filesystem and I can use something faster for us.\n\nThe all point of a design document isn\u0027t showcasing your implementation but rather brainstorming on a design that can meet the requirements of multiple Gerrit users.\n \n\u003e \u003e \u003e \u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\u003e \u003e \u003e \n\u003e \u003e \u003e This sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below).\n\u003e \u003e \n\u003e \u003e It is a storage alternative: using a proper pub/sub system for storing the replication events rather than a shared filesystem.\n\u003e \n\u003e My use case is not about improving the storage mechanism.\n\nSure, but not even degrading it.\n\n\u003e \u003e \u003e Technical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\u003e \u003e \n\u003e \u003e Have you seen the recent evolutions of the replication plugin, about refs filtering? It exposes an interface that is implemented by other plugins. It is possible and we use it also for the multi-site plugin. Happy to showcase how it works at the next forthcoming Gerrit User Summit \u0026 Hackathon in Sunnyvale :-)\n\u003e \n\u003e I look forward to hearing more about this.\n\n+1\n\n\u003e \u003e Gotcha, so it is one lock per repository. We will end up potentially creating tens of thousands of directories on the filesystem, which will be a major slowdown for NFS servers. NFS is very sensitive in terms of performance to the number of items in a directory.\n\u003e \n\u003e Since there are always fewer URI directories than task files, this solution will actually improve the current sharding over the current storage mechanism.\n\u003e \n\u003e \u003e Have you done some benchmarking on the slowdown generated by the implementation of those locks using individual directories?\n\u003e \n\u003e I have not benchmarked the current storage mechanism, it could be problematic for us, if it is I will work on sharding it better. However, this specific use case is not trying to solve that problem if it exists.\n\u003e \n\u003e As mentioned above, the proposed solution of putting the running tasks in a directory per URI should scale better than the current solution of putting all the running tasks in the same directory.\n\nNot really, because the current solution is using the local filesystem, which is very fast and has almost zero file attributes caching TTL. The proposed solution uses NFS, which is a completely different beast.",
      "parentUuid": "89a31b45_db839962",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "95f9cbdf_f132258f",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T21:08:19Z",
      "side": 1,
      "message": "\u003e The latency tomorrow with the storage of events on NFS is:\n\u003e T0) ref-update happens, replication event stored on NFS, with latency L time (for busy NFS servers, could even be 60 seconds)\n\u003e T1 \u003d T0 + L) replication starts\n\u003e \n\u003e The NFS solution increases latency by the NFS cache propagation time, which could be up to 2 minutes.\n\nThank you for explaining your specific concern here, it was not something I previously understood. It sounds like your concern here is about any extra write latency that moving the persisted task storage from a local filesystem to NFS would add?\n\nI believe that NFS caching does not come into play when writing, it only affects reads.\n\nI believe that if someone\u0027s shared filesystem is good enough for sharing their git repos (which it sounds like yours is not), then it is reasonable to assume they can tolerate any extra write latency enccured by this move in order to solve my use case since they will be tolerating this write latency also when writing their git objects and refs. This stems from the fact that writing a task file should be about the same as writing a loose ref update with jgit.\n\n\u003e The all point of a design document isn\u0027t showcasing your implementation but rather brainstorming\n\nThis doc is about my proposed design, not brainstorming. I agree that it is important for the community to stay open to other designs, and for me to be open to critic of this design.  Alternate designs may be uploaded in parallel for review. I do not believe it is up to me to provide alternate designs for this use case, or for alternate use cases.\n\n\u003e but rather brainstorming on a design that can meet the requirements of multiple Gerrit users.\n\nI believe that \"the requirements of multiple Gerrit users.\" here might be another way of saying \"different use cases\", which this solution need not address.\n\nI do not want my solution to make your situation worse than it is today, and it is important that you point out anywhere you believe it might. This being said, it is also important that you respect that I am not trying to solve all the problems you are facing unless they are the same as described by my use case.",
      "parentUuid": "b649d125_3014bc2f",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ebb0ea6b_15580f64",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T21:25:59Z",
      "side": 1,
      "message": "\u003e \u003e The latency tomorrow with the storage of events on NFS is:\n\u003e \u003e T0) ref-update happens, replication event stored on NFS, with latency L time (for busy NFS servers, could even be 60 seconds)\n\u003e \u003e T1 \u003d T0 + L) replication starts\n\u003e \u003e \n\u003e \u003e The NFS solution increases latency by the NFS cache propagation time, which could be up to 2 minutes.\n\u003e \n\u003e Thank you for explaining your specific concern here, it was not something I previously understood. It sounds like your concern here is about any extra write latency that moving the persisted task storage from a local filesystem to NFS would add?\n\nNFS cache TTL on read is the problem: the latency L time is when the other node sees the replication event. For us and some of our clients, that time when there is heavy load can be up to minutes.\n\n\u003e I believe that NFS caching does not come into play when writing, it only affects reads.\n\nYep, that\u0027s the issue.\n\n\u003e I believe that if someone\u0027s shared filesystem is good enough for sharing their git repos (which it sounds like yours is not), then it is reasonable to assume they can tolerate any extra write latency enccured by this move in order to solve my use case since they will be tolerating this write latency also when writing their git objects and refs. This stems from the fact that writing a task file should be about the same as writing a loose ref update with jgit.\n\nJGit already has the workarounds to deal with this problem: it just not trust the filesystem at all and does extra reads even when they are not needed.\n\n\u003e \u003e The all point of a design document isn\u0027t showcasing your implementation but rather brainstorming\n\u003e \n\u003e This doc is about my proposed design, not brainstorming. I agree that it is important for the community to stay open to other designs, and for me to be open to critic of this design.  Alternate designs may be uploaded in parallel for review. I do not believe it is up to me to provide alternate designs for this use case, or for alternate use cases.\n\nThat is not what has been proposed and agreed in the community, see:\nhttps://gerrit-review.googlesource.com/Documentation/dev-design-docs.html\n\n\"Possible Solutions: Possible solutions with the pros and cons, and explanation of implementation details.\"\n\nThis is exactly what this discussion is about: trying to analyse the pros and cons of possible solutions. If this solution, that works for you, would make other scenarios worse, then we need to discuss and come to an agreement.\n\nI do like the idea of scaling up the replication horizontally, as our clients have HA in place with a shared filesystem. I am just brainstorming on other possible (pluggable?) storage for the persistence of the events, so that the overall latency would not be worse than today.\n\n\u003e I believe that \"the requirements of multiple Gerrit users.\" here might be another way of saying \"different use cases\", which this solution need not address.\n\u003e \n\u003e I do not want my solution to make your situation worse than it is today, and it is important that you point out anywhere you believe it might. This being said, it is also important that you respect that I am not trying to solve all the problems you are facing unless they are the same as described by my use case.\n\nSure, but not making them worse either :-)",
      "parentUuid": "95f9cbdf_f132258f",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "40012896_c8670046",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T21:48:25Z",
      "side": 1,
      "message": "\u003e \u003e \u003e The latency tomorrow with the storage of events on NFS is:\n\u003e \u003e \u003e T0) ref-update happens, replication event stored on NFS, with latency L time (for busy NFS servers, could even be 60 seconds)\n\u003e \u003e \u003e T1 \u003d T0 + L) replication starts\n\u003e \u003e \u003e \n\u003e \u003e \u003e The NFS solution increases latency by the NFS cache propagation time, which could be up to 2 minutes.\n\u003e \u003e \n\u003e \u003e Thank you for explaining your specific concern here, it was not something I previously understood. It sounds like your concern here is about any extra write latency that moving the persisted task storage from a local filesystem to NFS would add?\n\u003e\n\u003e NFS cache TTL on read is the problem: the latency L time is when the other node sees the replication event. \n\nThe new task file should appear in other nodes directory listings with the same delay that a new loose ref will appear to the other nodes. The other node cannot begin to replicate until it sees the new loose ref, thus this task file delay does not impact replication on the other node.\n\n\u003e \u003e \u003e The all point of a design document isn\u0027t showcasing your implementation but rather brainstorming\n\u003e \u003e \n\u003e \u003e This doc is about my proposed design, not brainstorming. I agree that it is important for the community to stay open to other designs, and for me to be open to critic of this design.  Alternate designs may be uploaded in parallel for review. I do not believe it is up to me to provide alternate designs for this use case, or for alternate use cases.\n\u003e \n\u003e That is not what has been proposed and agreed in the community, see:\n\u003e https://gerrit-review.googlesource.com/Documentation/dev-design-docs.html\n\u003e \n\u003e \"Possible Solutions: Possible solutions with the pros and cons, and explanation of implementation details.\"\n\nFurther down it expands this to:\n\n\"Anyone who has ideas for an alternative solution uploads a change with a solution-\u003cn\u003e.md that describes their solution. In case of doubt whether an idea is a refinement of an existing solution or an alternative solution, it’s up to the owner of the discussed solution to decide if the solution should be updated, or if the proposer should start a new alternative solution.\"",
      "parentUuid": "ebb0ea6b_15580f64",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d1344fde_9bfda72c",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T21:58:35Z",
      "side": 1,
      "message": "\u003e \u003e \u003e \u003e The latency tomorrow with the storage of events on NFS is:\n\u003e \u003e \u003e \u003e T0) ref-update happens, replication event stored on NFS, with latency L time (for busy NFS servers, could even be 60 seconds)\n\u003e \u003e \u003e \u003e T1 \u003d T0 + L) replication starts\n\u003e \u003e \u003e \u003e \n\u003e \u003e \u003e \u003e The NFS solution increases latency by the NFS cache propagation time, which could be up to 2 minutes.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Thank you for explaining your specific concern here, it was not something I previously understood. It sounds like your concern here is about any extra write latency that moving the persisted task storage from a local filesystem to NFS would add?\n\u003e \u003e\n\u003e \u003e NFS cache TTL on read is the problem: the latency L time is when the other node sees the replication event. \n\u003e \n\u003e The new task file should appear in other nodes directory listings with the same delay that a new loose ref will appear to the other nodes. The other node cannot begin to replicate until it sees the new loose ref, thus this task file delay does not impact replication on the other node.\n\nThe file attributes, yes, the content, no.\n\nExample:\nT0) Node A updates refs/heads/master from C1 to C2\nT0) Node B does not see the refs/heads/master utime updated, but if he tries to read the refs/heads/master (aka try to replicate its value) it would see C2\n\nBottom line: if we \"tell\" Note B that refs/heads/master must be replicated now, it will be able to do it because will be able to re-read the loose ref. Remember that JGit has a workaround to the NFS caching for that reason.\n\nP.S.: I believe it would be best to continue the conversation at Sunnyvale with a whiteboard, otherwise we may crash the NoteDb on gerrit-review :-)\n\n\u003e \u003e \u003e \u003e The all point of a design document isn\u0027t showcasing your implementation but rather brainstorming\n\u003e \u003e \u003e \n\u003e \u003e \u003e This doc is about my proposed design, not brainstorming. I agree that it is important for the community to stay open to other designs, and for me to be open to critic of this design.  Alternate designs may be uploaded in parallel for review. I do not believe it is up to me to provide alternate designs for this use case, or for alternate use cases.\n\u003e \u003e \n\u003e \u003e That is not what has been proposed and agreed in the community, see:\n\u003e \u003e https://gerrit-review.googlesource.com/Documentation/dev-design-docs.html\n\u003e \u003e \n\u003e \u003e \"Possible Solutions: Possible solutions with the pros and cons, and explanation of implementation details.\"\n\u003e \n\u003e Further down it expands this to:\n\u003e \n\u003e \"Anyone who has ideas for an alternative solution uploads a change with a solution-\u003cn\u003e.md that describes their solution. In case of doubt whether an idea is a refinement of an existing solution or an alternative solution, it’s up to the owner of the discussed solution to decide if the solution should be updated, or if the proposer should start a new alternative solution.\"\n\nI do like your solution, I just want to understand its implications and see if you have considered alternative approaches.\n\nIt is not \"your\" or \"my\" solution, but rather we work together for \"our\" solution :-) I am more than happy also to actively support the implementation, review and testing. That\u0027s the spirit of OpenSource after all, working together even if we work in different companies with different goals.",
      "parentUuid": "40012896_c8670046",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2b95bdcb_a4a9575f",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T22:10:13Z",
      "side": 1,
      "message": "\u003e \u003e The new task file should appear in other nodes directory listings with the same delay that a new loose ref will appear to the other nodes. The other node cannot begin to replicate until it sees the new loose ref, thus this task file delay does not impact replication on the other node.\n\u003e \n\u003e The file attributes, yes, the content, no.\n\u003e \n\u003e Example:\n\u003e T0) Node A updates refs/heads/master from C1 to C2\n\u003e T0) Node B does not see the refs/heads/master utime updated, but if he tries to read the refs/heads/master (aka try to replicate its value) it would see C2\n\nI was specifically considering a NEW task file and a NEW loose ref, not a changing one.\n \n\u003e P.S.: I believe it would be best to continue the conversation at Sunnyvale with a whiteboard, otherwise we may crash the NoteDb on gerrit-review :-)\n\nI really don\u0027t think it would be appropriate to delay the approval of this solution that long.",
      "parentUuid": "d1344fde_9bfda72c",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    }
  ]
}