{
  "comments": [
    {
      "key": {
        "uuid": "07f24f33_47982701",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T21:04:13Z",
      "side": 1,
      "message": "Have you thought about other solutions not using a shared filesystem?",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d6aab8c4_4199c8bf",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T21:30:31Z",
      "side": 1,
      "message": "I discuss several alternatives in the doc, please take a look.",
      "parentUuid": "07f24f33_47982701",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "89eedb7d_1bf21f99",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T21:37:27Z",
      "side": 1,
      "message": "The only one I\u0027ve found is:\n\"Since the current filesystem based storage exists and can be enhanced fairly easily to satisfy the desired use case as a polling based sharing solution, the extra expense of other sharing solutions does not currently seem worth considering.\"\n\nCan you point me to the exact section where you analyse a non-shared filesystem based alternative for distributing the replication load across masters?",
      "parentUuid": "d6aab8c4_4199c8bf",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "39ec1d82_f93e93f0",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T21:55:25Z",
      "side": 1,
      "message": "That is what I am referring to. Please comment there if you don\u0027t understand or have more specific questions.",
      "parentUuid": "89eedb7d_1bf21f99",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4f697336_4fc8e80c",
        "filename": "pages/design-docs/scaling-multi-master-replication/index.md",
        "patchSetId": 5
      },
      "lineNbr": 12,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T22:01:31Z",
      "side": 1,
      "message": "OK, will comment there.",
      "parentUuid": "39ec1d82_f93e93f0",
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "cbe030ac_24945f56",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-22T22:01:31Z",
      "side": 1,
      "message": "The shared filesystem storage has problems too:\n- latency\n- concurrent locking\n- stale file handles\n- caching issues\n- lack of real-time notifications\n\nYou are basically saying that you did not believe it was worth to think about any other solution other than reusing the shared filesystem, just because it is there.\n\nI understand the point, however, it goes against the design-driven approach IMHO, where we asked whoever proposed a solution to think about other possible solutions.",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "852d4965_c80197b5",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-22T22:58:48Z",
      "side": 1,
      "message": "\u003e The shared filesystem storage has problems too:\n\n\u003e - latency\n\nI am assuming this is not a repeat of the concern below about \"real-time\", so perhaps it refers to persistence latency, and or directory listing latency? It likely has lower or comparable persistence latency to most other solutions. For this use case, the persistence latency does not seem to specifically be very important. As for directory listings, I believe there are many ways to improve the design via sharding and file attributes to decrease this latency if this becomes an issue. The lack of sharding is likely already a replication persistence problem with the current plugin and likely should be dealt with even without this solution.\n\n\u003e - concurrent locking\n\nI believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\n\u003e - stale file handles\n\nAside from potentially interrupting code execution, these are likely not disruptive since they are effectively file not founds which can easily be handled.\n\n\u003e - caching issues\n\nI believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\nWithout jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\n\u003e - lack of real-time notifications\n\nI think you mean event vs polling (since real-time and Gerrit are not really compatible)? I address this in the next section.\n\n\u003e You are basically saying that you did not believe it was worth to think about any other solution other than reusing the shared filesystem, just because it is there.\n\nI am saying that other storage mechanism have extra expenses and the expense list is huge. Here are some obvious expenses: developing a new persistent mechanism, adding external tools to maintain, likely lower reliability due to extra moving parts, likely more communication overhead, likely more libraries to manage with more version compatibility issues, likely more expertise needed to manage, likely more RAM usage, and the list goes on...\n\n\u003e I understand the point, however, it goes against the design-driven approach IMHO, where we asked whoever proposed a solution to think about other possible solutions.\n\nI believe I listed about 6 of them. It is true that I have not listed any explicit alternate sharing mechanisms as all the ones I can think of would suffer the extra expenses that I mention. Do you have any specific suggestions that you believe do not suffer extra expenses?",
      "parentUuid": "cbe030ac_24945f56",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a96e654d_7d9e9ee7",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T09:59:48Z",
      "side": 1,
      "message": "\u003e \u003e The shared filesystem storage has problems too:\n\u003e \n\u003e \u003e - latency\n\u003e \n\u003e I am assuming this is not a repeat of the concern below about \"real-time\", so perhaps it refers to persistence latency, and or directory listing latency? \n\nWith NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\nIn our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\nUsing other shared replication queue implementation (e.g. a message broker) would resolve this problem and reduce latency to msecs.\n\nWhy not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\n\u003e \u003e - concurrent locking\n\u003e \n\u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\nIt depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\nHaving something more granular, it would results in tens of thousands of directories that would eventually slow down the overall system.\n\n\u003e \u003e - stale file handles\n\u003e \n\u003e Aside from potentially interrupting code execution, these are likely not disruptive since they are effectively file not founds which can easily be handled.\n\nAck.\n\n\u003e \u003e - caching issues\n\u003e \n\u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \n\u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\nWe tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\n\u003e \u003e - lack of real-time notifications\n\u003e \n\u003e I think you mean event vs polling (since real-time and Gerrit are not really compatible)? I address this in the next section.\n\nAck.",
      "parentUuid": "852d4965_c80197b5",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c52d5e11_67dfb29c",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T17:26:02Z",
      "side": 1,
      "message": "\u003e With NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\nNo matter how long the shared filesystem delay is, it should not be problematic for the use case where the same shared filesystem is being used to share the git repos since the git data will be limited by this delay also. I.E. there is no point knowing about a pending replication event on another node before the git objects for that event are available to replicate on the other node.\n\n\u003e In our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\nI would like to ask that you please keep in mind the scope of the review of this solution to my use case (which is not about reducing latency).\n\n\u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\nThis sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below). \n\nTechnical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\n\u003e \u003e \u003e - concurrent locking\n\u003e \u003e \n\u003e \u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\u003e \n\u003e It depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\nPerhaps we are talking about different URIs than I am? I am talking about the URI in the current ReplicationTasksStorage.UriUpdate.uri object, perhaps you are talking about the entry in the replication.config file? My approach leads to the same level of locking that is currently seen with a single node. For my use case it is desirable to keep this level of locking in order to prevent having more masters from adding more load to destination resources than the load created by a single node.\n\n\u003e \u003e \u003e - caching issues\n\u003e \u003e \n\u003e \u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \u003e \n\u003e \u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\u003e \n\u003e We tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\nOn second thought, I don\u0027t believe this is relevant since as I pointed out above, having replication coordination that is faster than git coordination does not provide any benefit to the use case being solved.",
      "parentUuid": "a96e654d_7d9e9ee7",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2c85412f_c242e70e",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1006192
      },
      "writtenOn": "2019-10-24T19:27:12Z",
      "side": 1,
      "message": "\u003e \u003e With NFS, the other nodes could see new files seconds or even minutes afterwards. Adding 1-2 mins delay to all existing replications could be a serious issue.\n\u003e \n\u003e No matter how long the shared filesystem delay is, it should not be problematic for the use case where the same shared filesystem is being used to share the git repos since the git data will be limited by this delay also. I.E. there is no point knowing about a pending replication event on another node before the git objects for that event are available to replicate on the other node.\n\nNFS is caching the files attributes, not the file content. If you know that a file exists on the other node, you will be able to read it. The problem is that you cannot discover that the file exists through attributes because they are cached and thus can\u0027t be trusted. (see the trustfolderstats flag in JGit config)\n\n\u003e \u003e In our use-case, we use HA and multi-site, we want to reduce the replication latency from tens of seconds to less than 1 sec: this solution won\u0027t be helpful.\n\u003e \n\u003e I would like to ask that you please keep in mind the scope of the review of this solution to my use case (which is not about reducing latency).\n\nScalability means not increasing latency also, but keep the same comparable level of service.\n\n\u003e \u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\u003e \n\u003e This sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below).\n\nIt is a storage alternative: using a proper pub/sub system for storing the replication events rather than a shared filesystem.\n\n\u003e Technical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\nHave you seen the recent evolutions of the replication plugin, about refs filtering? It exposes an interface that is implemented by other plugins. It is possible and we use it also for the multi-site plugin. Happy to showcase how it works at the next forthcoming Gerrit User Summit \u0026 Hackathon in Sunnyvale :-)\n\n\u003e \u003e \u003e \u003e - concurrent locking\n\u003e \u003e \u003e \n\u003e \u003e \u003e I believe for this simple use case this likely is on par with other solutions, see the locking prototype here: https://gerrit-review.googlesource.com/c/plugins/replication/+/241132\n\u003e \u003e \n\u003e \u003e It depends on how many destinations you have. In our case we have tens of thousands with the same URI but different credentials and associated projects. Locking by URI would result in everyone stuck on the same lock.\n\u003e \n\u003e Perhaps we are talking about different URIs than I am? I am talking about the URI in the current ReplicationTasksStorage.UriUpdate.uri object, perhaps you are talking about the entry in the replication.config file? My approach leads to the same level of locking that is currently seen with a single node. For my use case it is desirable to keep this level of locking in order to prevent having more masters from adding more load to destination resources than the load created by a single node.\n\nGotcha, so it is one lock per repository. We will end up potentially creating tens of thousands of directories on the filesystem, which will be a major slowdown for NFS servers. NFS is very sensitive in terms of performance to the number of items in a directory.\n\nHave you done some benchmarking on the slowdown generated by the implementation of those locks using individual directories?\n\n\u003e \u003e \u003e \u003e - caching issues\n\u003e \u003e \u003e \n\u003e \u003e \u003e I believe that many of the current Gerrit NFS caching issues are due to the jgit caching layers which are hard to workaround.\n\u003e \u003e \u003e \n\u003e \u003e \u003e Without jgit in the way these should not be a big challenge. The files are currently immutable so they have no caching issues. In my experience refreshing parent directories will refresh any operation that uses directory listings on the child directory. It probably would be good (and easy) to build that into the plugin.\n\u003e \u003e \n\u003e \u003e We tried that workaround, it works for your NFS implementation but did not for others. We cannot force a solution that would work only in very specific situations.\n\u003e \n\u003e On second thought, I don\u0027t believe this is relevant since as I pointed out above, having replication coordination that is faster than git coordination does not provide any benefit to the use case being solved.\n\nSee my comment above: I am talking about caching of the file attributes, not of the file contents.",
      "parentUuid": "c52d5e11_67dfb29c",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "89a31b45_db839962",
        "filename": "pages/design-docs/scaling-multi-master-replication/solution-distribute-replication-tasks-via-shared-FS.md",
        "patchSetId": 5
      },
      "lineNbr": 283,
      "author": {
        "id": 1003883
      },
      "writtenOn": "2019-10-24T19:47:24Z",
      "side": 1,
      "message": "\u003e NFS is caching the files attributes, not the file content. If you know that a file exists on the other node, you will be able to read it. The problem is that you cannot discover that the file exists through attributes because they are cached and thus can\u0027t be trusted. (see the trustfolderstats flag in JGit config)\n\nI am not sure how you think this affects my particular use case, maybe you can read the rest of the solution and position this concern on the specific piece that you think would be problematic. I am only planning on using file attributes (the time) as a reference point for scheduling delays.\n\n\u003e Scalability means not increasing latency also, but keep the same comparable level of service.\n\nAgreed, do you see a specific place where this would be reduced by this solution over the current replication plugin?\n\n\u003e \u003e \u003e Why not making the replication queue storage pluggable with a DynamicItem? The filesystem-based implementation, that would be best for your use-case, could stay as a default implementation. However, we could also play a message broker and having msecs latency instead.\n\u003e \u003e \n\u003e \u003e This sounds like the domain of a follow on use case for those who want it (see \"Task distribution alternatives\" below).\n\u003e \n\u003e It is a storage alternative: using a proper pub/sub system for storing the replication events rather than a shared filesystem.\n\nMy use case is not about improving the storage mechanism.\n\n\u003e \u003e Technical note: currently, I don\u0027t believe plugins can define their own DynamicItem without core registering the type as a DynamicItem. Since this would be a replication plugin type, core would not be aware of it to define it.\n\u003e \n\u003e Have you seen the recent evolutions of the replication plugin, about refs filtering? It exposes an interface that is implemented by other plugins. It is possible and we use it also for the multi-site plugin. Happy to showcase how it works at the next forthcoming Gerrit User Summit \u0026 Hackathon in Sunnyvale :-)\n\nI look forward to hearing more about this.\n\n\u003e Gotcha, so it is one lock per repository. We will end up potentially creating tens of thousands of directories on the filesystem, which will be a major slowdown for NFS servers. NFS is very sensitive in terms of performance to the number of items in a directory.\n\nSince there are always fewer URI directories than task files, this solution will actually improve the current sharding over the current storage mechanism.\n\n\u003e Have you done some benchmarking on the slowdown generated by the implementation of those locks using individual directories?\n\nI have not benchmarked the current storage mechanism, it could be problematic for us, if it is I will work on sharding it better. However, this specific use case is not trying to solve that problem if it exists.\n\nAs mentioned above, the proposed solution of putting the running tasks in a directory per URI should scale better than the current solution of putting all the running tasks in the same directory.",
      "parentUuid": "2c85412f_c242e70e",
      "range": {
        "startLine": 282,
        "startChar": 54,
        "endLine": 283,
        "endChar": 41
      },
      "revId": "b6f79addb0d55e733c634722208983a1bda201ea",
      "serverId": "173816e5-2b9a-37c3-8a2e-48639d4f1153",
      "unresolved": true
    }
  ]
}